/**
 COPYRIGHT (C) 2015 Scot Matson. All Rights Reserved

 Code Review and Performance Report

 Solves CS147 Homework Assignment #06

 @author Scot Matson
 @version 2015/08/01
 */

While this assignment was noted as possibly being one of the easier ones in the
semester, I had found myself having a great deal of difficulty in the initial phases
of development. Much of this was due to time management issues but more so I believe
from the fact that this assignment brought about concepts that were completely
foreign to me. Previous assignments had all somewhat felt familiar and had much of
the code already developed whereas the only information we had to go on in assignment 06
was brief explanations paired with pseudocode.

Looking over the various algorithms I was going to be implementing I looked for
commonalities between them as a way to better understand what I was up against.
I had concluded (and was fortunately right) that once I had managed to break through
my mental barrier and complete an initial basic algorithm, the rest of the assignment
would be much more easily completed. I began by building my development environment,
a rather simple framework of the classes I thought I would be needing. I also dropped
into each class a commented out block of psuedocode from the book for a reference.

Since I was still really unsure about what the terminology of graphing algorithms
really meant, I spent quite a bit of time just trying to break concepts down into
their constituent forms. Graphs, edges, vertices, weights, spanning trees, etc.
It was a lot of information to dig through but well worth the time. While explanations
in the book still felt wordy and incomplete, I found a wealth of information on the web
that was quickly filling in the blanks. The greatest factor which really left me
feeling prepared to move forward with tackling the first of five different algorithms
was taking the time to diagram and fill in a table of my own, in essence, I was
walking through the topological sorting algorithm by hand. This level of closeness
to these new concepts opened my mind to a new way of thinking but it didn't
necessarily mean that I had yet understood how to translate my knowledge of this
algorithm into a programmatic language.

The next step towards my understanding was a mixture of finding implementations of
a topological sorting algorithm on the web and reading through them, all the while
looking for common programming patterns. After doing this a couple of times I started
to really see what Mark Allen Weiss was describing in his psuedocode. The next
evolution in my development cycle was uncommenting the psuedocode which I pasted into
my class, line-by-line. As each new line was revealed many new error messages would
appear. I took that as initiative to find a way to create and implement that missing
features. While this process was slow, and had many false starts, over time it really
paid off. When my topological sort reached a point where I could potentially run
the application, I was not surprisingly bombarded with Exceptions. Using the
debugger extensively allowed me to quickly locate each and every Cycle, NullPointer,
and IllegalState that was being thrown.

With my topological sort completed, I felt I had reached a point of enlightenment.
Reading the other areas in the book became much more clear and the psuedocode was
suddenly easy to follow. So while implementing algorithms became easier, I found that
generating output for testing became increasingly difficult. These algorithms
had many moving pieces and typically I really do not like mixing my IO code heavily
into my algorithms but for the sake of functionality and getting the desired results
this is exactly what I did. Given more time, I think the first thing I would like to
work on is how I am handling IO. I'd really like to find a way to cleanly separate it
into its own class which I could just pass data into.

The unweighted, weighted, and Prims algorithms all felt so similar to me that once
I had a working copy of the unweighted algorithm. It just came down to adding
weights into the weighted algorithm, and then changing how weight was calculated
in the prim's algorithm. The only trouble that Prim's gave me was that I initially
was not marking Vertices as `found` and was relying on the distance variable to
handle this instead, as you can see from my implementation of the unweighted/weighted
algorithms. So what was occurring was that Vertices in every case were always taking
the lowest weighted Edge and essentially creating Disjunct pairs rather than a MST.
Fortunately I was quick to realize the solution was to not only assess weight
but also ensure that we were comparing a known Vertex with an unknown Vertex.

So this assignment ended up being completed in under 24 hours and quite possibly
had the greatest turnaround time for me than any other assignment. The only
algorithm in the end that still somewhat escapes me is Kruskal's Algorithm. I
understand the concept of it, using Edges as the driving force rather than Vertices;
but I was unable to really get the algorithm working as it was written in the book.
I ended up stumbling across an almost perfect drop-in snippet of Kruskal's which
I decided to implement. I still had to make some minor modifications but it really
worked incredibly well on its own. Despite probably needing more time to better
understand how Kruskal's algorithm works, I have learned a lot of about the graph
data structure and how to interact with it. I think the way it is diagrammed in
real life can make the code feel much more abstract that it is. I'm interested to
know how well these algorithms scale since we have been using a very small
set of Vertices during all of these tests.

Certain areas in my early phases of development keep making ponder my design
decisions later on, such as keeping Edges separate from my Vertex class, or
creating methods in my Graph class that were incredibly over-sized lists of
Vertices and Edges. I had refactored my code numerous times, often throwing
away many methods and classes after realizing I was moving in the wrong
direction; but all the while moving in the right direction at the same time.
I imagine given more time, these missteps which lead to new revelations are
often what fuel a complete code restructuring from the ground up.